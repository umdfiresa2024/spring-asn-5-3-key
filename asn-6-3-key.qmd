---
title: "ASN6.3. Paper Replication: Make Table 1"
author: "2022 FIRE198 Sustainability Analytics"
format: html
editor: visual
---

In this assignment you will use the functions that you have learned to replicate the Pollution emissions and Air quality section of Table 1 in *Defensive Investments and the Demand for Air Quality: Evidence from the NOx Budget Program* by DeschÃªnes, Greenstone, Shapiro.

![](T1.PNG){fig-align="center" width="400"}

### Part 1: Pollution Emissions

#### Step 1 (1 point)

Declare that you will use the **tidyverse** and **lubridate** package.

```{r}
library("tidyverse")
library("lubridate")
```

#### Step 2 (2 points)

Upload pollution emissions data from the year 2001 to 2007 into the environment and combine them together into one dataframe called **df.**

```{r}
df2001<-read.csv("EPA AMPD/emission_2001.csv")
df2002<-read.csv("EPA AMPD/emission_2002.csv")
df2003<-read.csv("EPA AMPD/emission_2003.csv")
df2004<-read.csv("EPA AMPD/emission_2004.csv")
df2005<-read.csv("EPA AMPD/emission_2005.csv")
df2006<-read.csv("EPA AMPD/emission_2006.csv")
df2007<-read.csv("EPA AMPD/emission_2007.csv")

df<-rbind(df2001, df2002, df2003, df2004, df2005, df2006, df2007)
```

#### Question 1: What is the unit of NOx, SO2, and CO2 pollution emissions in Table 1? Fill in the blank. **(3 points)**

#### Answer: \_\_\_Thousand\_\_ tons per \_\_\_\_\_ (state/city/county) during the \_\_\_summer\_\_\_ months of each year.

#### Step 3 (4 points)

Create a new dataframe named **df2** which has the total **summertime** NOx, SO2, and CO2 emissions (in **thousand tons**) for each **County**, **State**, and **Year**. Note that the summer months include May through September.

```{r}
df2<-df %>%
  filter(Month>=5 & Month<=9) %>%
  mutate(NOx=ifelse(!is.na(NOx..tons.), NOx..tons., 0)) %>%
  mutate(SO2=ifelse(!is.na(SO2..tons.), SO2..tons., 0)) %>%
  mutate(CO2=ifelse(!is.na(CO2..short.tons.), CO2..short.tons., 0)) %>%
  group_by(County, State, Year) %>%
  summarize(NOx=sum(NOx)/1000, SO2=sum(SO2)/1000, CO2=sum(CO2)/1000)
```

#### Step 4 (1 point)

Upload the **counties_t2a.csv** file into the environment. Name the dataframe **counties**. This dataframe is the list of all counties that satisfies the selection criteria in the paper *Defensive Investments and the Demand for Air Quality: Evidence from the NOx Budget Program.*

![](emit_data.JPG){fig-align="center" width="400"}

```{r}
counties<-read.csv("counties_t2a.csv")
```

#### Step 5

We need to make a balanced panel with all the counties and year that we are interested in.

This can be done by first creating a vector of all the years we are interested in. Afterward, we will use the **crossing** function to create a combination of all the counties and year we are interested in. Since we have 7 years and 2253 counties, the balanced panel will have 7 x 2,253 = 15,771 observations.

The code is shown below. You just have to run it.

```{r}

Year<-seq(2001,2007,by=1)

cy<-crossing(counties, Year)
```

Next, we will add the emissions data from **df2** into **cy**.

#### Question 2: What three variables do df2 and cy have in common? (3 points)

#### Answer: State, County, Year

#### Step 6 (3 points)

Add the emissions data from **df2** into **cy** by using the **merge** function by matching observations that has the same **State**, **County**, and **Year**.

Name the merged dataframe **emit.**

Make sure that the dataframe **emit** has all the observations in **cy**, but not the observations in **df2** that does not match with **cy**.

```{r}
emit<-merge(cy, df2, by=c("State", "County", "Year"), all.x=TRUE)
```

#### Step 7 (2 points)

Create a new dataframe named **emit_mean** from **emit.**

Replace all the NA values that the columns that represent NOx, SO2, and CO2 emissions with 0.

Afterward, use the **summarize** and **mean** function to find the average NOx, SO2, and CO2 emissions across all counties and years. Name the variables **mean_NOx**, **mean_SO2**, and **mean_CO2**.

```{r}
emit_mean<-emit %>%
  mutate(NOx=ifelse(!is.na(NOx), NOx, 0)) %>%
  mutate(SO2=ifelse(!is.na(SO2), SO2, 0)) %>%
  mutate(CO2=ifelse(!is.na(CO2), CO2, 0)) %>%
  summarize(mean_SO2=mean(SO2), mean_CO2=mean(CO2), mean_NOx=mean(NOx))
```

#### Step 8 (2 points)

Create a new dataframe named **emit_sd** from **emit.**

Replace all the NA values that the columns that represent NOx, SO2, and CO2 emissions with 0.

Afterward, use the **summarize** and **sd** function to find the standard deviation of NOx, SO2, and CO2 emissions across all counties and years. Name the variables **sd_NOx**, **sd_SO2**, and **sd_CO2**.

```{r}
emit_sd<-emit %>%
  mutate(NOx=ifelse(!is.na(NOx), NOx, 0)) %>%
  mutate(SO2=ifelse(!is.na(SO2), SO2, 0)) %>%
  mutate(CO2=ifelse(!is.na(CO2), CO2, 0)) %>%
  summarize(sd_SO2=sd(SO2), sd_CO2=sd(CO2), sd_NOx=sd(NOx))
```

#### Step 9

We will use the **pivot_longer** function to format our results in table format of the original paper. The code is shown below. You just have to run it.

```{r}
mean_long<-pivot_longer(emit_mean,
                        cols=1:3,
                        names_to = "Pollution emissions (000's of tons/summer)",
                        names_prefix="mean_", 
                        values_to = "Mean") 

sd_long<-pivot_longer(emit_sd,
                        cols=1:3,
                        names_to = "Pollution emissions (000's of tons/summer)",
                        names_prefix="sd_", 
                        values_to = "SD") 

T1a<-merge(mean_long, sd_long, 
           by="Pollution emissions (000's of tons/summer)") %>%
  mutate(n=nrow(counties)) 

print(T1a)
```

#### Question 3: Compare the mean of NOx, standard deviation of NOx, and counties with data to the numbers presented in the original paper. Which ones are greater? (3 points)

#### Answer: Our mean is larger, our sd is larger, but the number of counties we have is less.

**Step 10**

Run the script below to clear the environment so that we can use the disk space for more data.

```{r}
rm(list = ls())
```

### Part 2: Air Quality

#### Step 1

Each .csv file in the **EPA Air Data** folder records daily NO2 concentrations for each county in the United States. The **dir** function can be used to make a vector of all files in the EPA Air Data folder.

The below makes a list of files in the **EPA Air Data** folder. You just have to run it.

```{r}
files<-dir("EPA Air Data")
```

#### Step 2

The **paste0** function can be used to combine characters together. For example, the script below combines **"EPA Air Data/"** and the characters in **files\[1\]**. You just have to run it.

```{r}
paste0("EPA Air Data/",files[1])
```

#### Step 3

The script below uploads the first file in the folder **EPA Air Data** into the environment and stores it as the dataframe **air01**. You just have to run it.

```{r}
air01<-read.csv(paste0("EPA Air Data/",files[1]))
```

#### Step 4 (2 points)

Upload all of the files in the **EPA Air Data** folder and combine them into one dataframe named **air.**

```{r}
air02<-read.csv(paste0("EPA Air Data/",files[2]))
air03<-read.csv(paste0("EPA Air Data/",files[3]))
air04<-read.csv(paste0("EPA Air Data/",files[4]))
air05<-read.csv(paste0("EPA Air Data/",files[5]))
air06<-read.csv(paste0("EPA Air Data/",files[6]))
air07<-read.csv(paste0("EPA Air Data/",files[7]))

air<-rbind(air01, air02, air03, air04, air05, air06, air07)
```

#### Step 5 (1 point)

Use the rm function to remove other dataframes except **air** in the environment.

```{r}
rm(air01, air02, air03, air04, air05, air06, air07)
```

#### Step 6

The script below creates four new variables: **week** represents the week number of each year, **month** represents the month number of each year, **year** represents the year number, **fips** is the state-county identifier. You just have to run it.

```{r}
air2<-air %>%
  mutate(date=as.Date(Date.Local), format="%Y-%m-%d") %>%
  mutate(week=week(date)) %>%
  mutate(month=month(date)) %>%
  mutate(year=year(date)) %>%
  mutate(fips=as.numeric(State.Code)*1000+County.Code)
```

#### Step 7 (2 points)

Create a vector that contains unique values of **fips** in the dataframe **counties**. Name the vector **fips_num**.

Create a new dataframe named **air3** from **air2**, but include only the counties in **fips_num**. These are the counties that were regulated by the NOx Budget Program.

```{r}
counties<-read.csv("counties_t2a.csv")

fips_num<-unique(counties$fips)

air3<-air2 %>%
  filter(fips %in% fips_num)
```

Steps 8 through 10 will let us also identify counties that satisfy the criteria below.

![](air_data.JPG){fig-align="center" width="400"}

#### Step 8

The script below finds the number of air quality observations per week in each county. You just have to run it.

```{r}
air4<-air3 %>%
  group_by(week, year, fips) %>%
  tally()
```

#### Step 9 (4 points)

Create a new dataframe called **air5** from **air4**. Use the **group_by** and **tally** function to find the **number of weeks** for each county and year.

Afterward, keep only counties with at least 47 weeks in a year.

```{r}
air5<-air4 %>%
  group_by(fips, year) %>%
  tally() %>%
  filter(n>=47)
```

#### Step 10 (4 points)

Create a new dataframe called **air6** from **air5**. Use the **group_by** and **tally** function to find the **number of years** for each county that reported at least 47 weeks of data.

Afterward, keep only counties with 7 years of data with at least 47 weeks of data in each year.

```{r}
air6<-air5 %>%
  group_by(fips) %>%
  tally() %>%
  filter(n==7)
```

#### Question 4: How many counties included in the *Defensive Investments* paper have 7 years of data with at least 47 weeks of data in each year? (1 point)

#### Answer: 95 counties

#### Step 11 (4 points)

Create a new dataframe named **air7** from the dataframe **air2**.

Keep only counties in the dataframe **air6**.

Afterward, find the average NO2 levels in the summer months (May through September) for each county. Note that the column **Arithmetic.Mean** in dataframe **air2** represents the daily NO2 level.

```{r}
air7<-air2 %>%
  filter(fips %in% air6$fips) %>%
  filter(month>=5 & month<=9) %>%
  group_by(fips) %>%
  summarize(NO2=mean(Arithmetic.Mean)) 
```

#### Step 12 (3 points)

Find the average, standard deviation, and the number of observations of NO2 across all counties.

```{r}
NO2<-air7 %>%
  summarize(mean_NO2=mean(NO2), sd_NO2=sd(NO2), n=n())

print(NO2)
```

#### Question 5: Compare the mean of NO2, standard deviation of NO2, and number of counties with data to the numbers presented in the original paper. Which ones are greater? (3 points)

#### Answer: Our mean is less, our sd is larger, and the number of counties we have is less.

#### Step 13

Run the script below to make space for more data.

```{r}
rm(list = ls())
```

### Part 3

#### Step 1

Go to the [EPA's website](https://aqs.epa.gov/aqsweb/airdata/download_files.html) and download **Daily Summary Data** from the year 2001 to 2007 for one of the regulated gases or particulates. You can choose between **Ozone (44201)**, **SO2 (42401)**, **CO (42101)**, **PM2.5 (88101)**, **PM10 (81102).**

#### Question 6: Which gas or particulate class will you work on? (1 point)

#### Answer:

#### Step 2 (1 point)

Upload the .zip files into Posit Cloud by clicking on the Upload icon on the bottom right panel. Note that you need to upload each .zip file at a time.

![](upload_icon.png){fig-align="center" width="400"}

#### Step 3 (1 point)

Edit the character in the script below so that it matches the EPA's air pollution code. For example, PM2.5 is "88101" as shown below.

```{r}
files<-dir(, pattern = "88101")
```

#### Step 4 (6 points)

Repeat Part 2 Steps 4 through 12

#### Question 7: Compare the mean, standard deviation, and number of counties to the numbers presented in the original paper. Which ones are greater? (3 points)

#### Answer:

You have reached the end of the assignment. Save the Quarto document and push the completed assignment back into the GitHub repository.
